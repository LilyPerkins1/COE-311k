{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: [3396993125857097728 6892060737523348480 3013160365829545984\n",
      " 6892060737523348480 3396993125857097728]\n",
      "Iterations: 1000\n",
      "Time of execution: \n",
      " 0.06873 seconds\n",
      "\n",
      "\n",
      "We can identify by the massive scale of the numbers that this method has failed and is unable to converge on a solution. This is supported by the structure of the matrix, in which the primary diagonal isn't dominant. It takes 0.07 to go through 1000 iterations, which is why I set the upper limit to the number of iterations allowed. If I had given it more iterations, it would have hit the upper limit, because this will never converge by this method. The reason that this matrix diverges, while 6a converges lies in the relative size of the primary diagonal. 6a was dominant, this one wasn't.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-955e62971f4c>:10: RuntimeWarning: overflow encountered in long_scalars\n",
      "  s = sum(A[i][j] * x[j] for j in range(n) if j != i)\n"
     ]
    }
   ],
   "source": [
    "#jacobi\n",
    "import time\n",
    "import numpy as np\n",
    "def jacobi(A, b, x0, tol, max_iterations):\n",
    "    n = len(b)\n",
    "    x = x0.copy()\n",
    "    for k in range(max_iterations):\n",
    "        x_new = np.zeros_like(x)\n",
    "        for i in range(n):\n",
    "            s = sum(A[i][j] * x[j] for j in range(n) if j != i)\n",
    "            x_new[i] = (b[i] - s) / A[i][i]\n",
    "# Check for convergence\n",
    "        if np.linalg.norm(x_new - x, ord=np.inf) < tol:\n",
    "            return x_new, k\n",
    "        x = x_new\n",
    "        if i == 500:\n",
    "            print(\"500th X is: \", x)\n",
    "    return x, max_iterations\n",
    "\n",
    "# Example usage\n",
    "A = np.array([[1,2,3,0,0],\n",
    "              [2,1,2,3,0],\n",
    "              [3,2,1,2,3],\n",
    "              [0,3,2,1,2],\n",
    "              [0,0,3,2,1]])\n",
    "\n",
    "b = np.array([14, 22, 33, 26, 22])\n",
    "x0 = np.zeros_like(b)\n",
    "tol = 1e-6\n",
    "max_iterations = 1000\n",
    "              \n",
    "start_time = time.perf_counter()\n",
    "solution, iterations = jacobi(A, b, x0, tol, max_iterations)\n",
    "end_time = time.perf_counter()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Solution: {solution}\")\n",
    "print(f\"Iterations: {iterations}\")\n",
    "print(\"Time of execution: \")\n",
    "print(f\" {total_time:.5f}\", \"seconds\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"We can identify by the massive scale of the numbers that this method has failed and is unable to converge on a solution. This is supported by the structure of the matrix, in which the primary diagonal isn't dominant. It takes 0.07 to go through 1000 iterations, which is why I set the upper limit to the number of iterations allowed. If I had given it more iterations, it would have hit the upper limit, because this will never converge by this method. The reason that this matrix diverges, while 6a converges lies in the relative size of the primary diagonal. 6a was dominant, this one wasn't.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: [-3222725436718121984 -6880488481881970688 -5296794635246657536\n",
      " -8477445564595290112 -4048213112488550400]\n",
      "Iterations: 1000\n",
      "Time of execution: \n",
      " 0.07255 seconds\n",
      "\n",
      "\n",
      "We can identify by the massive scale of the numbers that this method has failed and is unable to converge on a solution. This is supported by the structure of the matrix, in which the primary diagonal isn't dominant. It takes 0.066 seconds to go through 1000 iterations, which is why I set the upper limit to the number of iterations allowed. If I had given it more iterations, it would have hit the upper limit, because this will never converge by this method. However, the Gauss-seidel method did iterate much quicker than the Jacobi method, proving its increase efficiency. The reason that this matrix diverges, while 6a converges lies in the relative size of the primary diagonal. 6a was dominant, this one wasn't.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-ecccdaa32ee0>:12: RuntimeWarning: overflow encountered in long_scalars\n",
      "  s1 = sum(A[i][j] * x_new[j] for j in range(i)) # Using already updated values\n",
      "<ipython-input-17-ecccdaa32ee0>:13: RuntimeWarning: overflow encountered in long_scalars\n",
      "  s2 = sum(A[i][j] * x[j] for j in range(i + 1, n)) # Using old values\n",
      "<ipython-input-17-ecccdaa32ee0>:14: RuntimeWarning: overflow encountered in long_scalars\n",
      "  x_new[i] = (b[i] - s1 - s2) / A[i][i]\n"
     ]
    }
   ],
   "source": [
    "#gauss-Seidel\n",
    "#leads to faster convergence\n",
    "import numpy as np\n",
    "def gauss_seidel(A, b, x0, tol, max_iterations):\n",
    "    n = len(b)\n",
    "    x = x0.copy()\n",
    "    \n",
    "    for k in range(max_iterations):\n",
    "        x_new = x.copy()\n",
    "        for i in range(n):\n",
    "            \n",
    "            s1 = sum(A[i][j] * x_new[j] for j in range(i)) # Using already updated values\n",
    "            s2 = sum(A[i][j] * x[j] for j in range(i + 1, n)) # Using old values\n",
    "            x_new[i] = (b[i] - s1 - s2) / A[i][i]\n",
    "        \n",
    "# Check for convergence\n",
    "        if np.linalg.norm(x_new - x, ord=np.inf) < tol:\n",
    "            return x_new, k\n",
    "        x = x_new\n",
    "\n",
    "    return x, max_iterations\n",
    "\n",
    "A = np.array([[1,2,3,0,0],\n",
    "              [2,1,2,3,0],\n",
    "              [3,2,1,2,3],\n",
    "              [0,3,2,1,2],\n",
    "              [0,0,3,2,1]])\n",
    "\n",
    "b = np.array([14, 22, 33, 26, 22])\n",
    "x0 = np.zeros_like(b)\n",
    "tol = 1e-6\n",
    "max_iterations = 1000\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "solution, iterations = gauss_seidel(A, b, x0, tol, max_iterations)\n",
    "end_time = time.perf_counter()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"Solution: {solution}\")\n",
    "print(f\"Iterations: {iterations}\")\n",
    "print(\"Time of execution: \")\n",
    "print(f\" {total_time:.5f}\", \"seconds\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"We can identify by the massive scale of the numbers that this method has failed and is unable to converge on a solution. This is supported by the structure of the matrix, in which the primary diagonal isn't dominant. It takes 0.066 seconds to go through 1000 iterations, which is why I set the upper limit to the number of iterations allowed. If I had given it more iterations, it would have hit the upper limit, because this will never converge by this method. However, the Gauss-seidel method did iterate much quicker than the Jacobi method, proving its increase efficiency. The reason that this matrix diverges, while 6a converges lies in the relative size of the primary diagonal. 6a was dominant, this one wasn't.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
